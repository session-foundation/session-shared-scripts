#!/usr/bin/env python3
"""
Desktop Localization Code Generator

Generates TypeScript files for Session Desktop localization `ts/localization/generated/`:
- locales.ts: Types, utility functions, and re-exports
- constants.ts: Localization constants.
- english.ts: English strings (editable by devs for local work)
- translations.ts: Sparse translations for other locales (only actual translations, no duplicated English)
"""

import argparse
import re
import os
from typing import Dict, List, Any, Tuple
from generate_shared import (
    load_parsed_translations,
    print_progress,
    print_success,
    run_main
)

# Mapping of variable names to their TypeScript "With*" type names
WITH_MAP = {
    ("name", "string"): "WithName",
    ("group_name", "string"): "WithGroupName",
    ("community_name", "string"): "WithCommunityName",
    ("other_name", "string"): "WithOtherName",
    ("author", "string"): "WithAuthor",
    ("emoji", "string"): "WithEmoji",
    ("emoji_name", "string"): "WithEmojiName",
    ("admin_name", "string"): "WithAdminName",
    ("time", "string"): "WithTime",
    ("time_large", "string"): "WithTimeLarge",
    ("time_small", "string"): "WithTimeSmall",
    ("disappearing_messages_type", "string"): "WithDisappearingMessagesType",
    ("conversation_name", "string"): "WithConversationName",
    ("file_type", "string"): "WithFileType",
    ("date", "string"): "WithDate",
    ("date_time", "string"): "WithDateTime",
    ("message_snippet", "string"): "WithMessageSnippet",
    ("query", "string"): "WithQuery",
    ("version", "string"): "WithVersion",
    ("information", "string"): "WithInformation",
    ("device", "string"): "WithDevice",
    ("percent_loader", "string"): "WithPercentLoader",
    ("message_count", "string"): "WithMessageCount",
    ("conversation_count", "string"): "WithConversationCount",
    ("found_count", "number"): "WithFoundCount",
    ("hash", "string"): "WithHash",
    ("url", "string"): "WithUrl",
    ("account_id", "string"): "WithAccountId",
    ("count", "number"): "WithCount",
    ("service_node_id", "string"): "WithServiceNodeId",
    ("limit", "string"): "WithLimit",
    ("relative_time", "string"): "WithRelativeTime",
    ("icon", "string"): "WithIcon",
    ("storevariant", "string"): "WithStoreVariant",
    ("min", "string"): "WithMin",
    ("max", "string"): "WithMax",
}

LOCALE_KEY_MAPPING = {
    'en-US': 'en',
    'kmr-TR': 'kmr',
    'hy-AM': 'hy-AM',
    'es-419': 'es-419',
    'pt-BR': 'pt-BR',
    'pt-PT': 'pt-PT',
    'zh-CN': 'zh-CN',
    'zh-TW': 'zh-TW',
    'sr-CS': 'sr-CS',
    'sr-SP': 'sr-SP'
}

DISCLAIMER_GENERATED = """// Do not modify this file manually. This file was generated by a script
// at https://github.com/session-foundation/session-shared-scripts
// Translations can be changed at https://getsession.org/translate

"""

DISCLAIMER_ENGLISH = """// English strings. Other locales will fall back to these strings when
// translations are missing.

"""


def get_locale_key(locale: str, two_letter_code: str) -> str:
    return LOCALE_KEY_MAPPING.get(locale, LOCALE_KEY_MAPPING.get(two_letter_code, two_letter_code))


def escape_str(value: str) -> str:
    """Escapes chars that would break the .ts: newlines and quotes."""
    return value.replace("\n", "\\n").replace("\'", "\\\'")


def wrap_value(value: str) -> str:
    """Wraps the given value in single quotes if it contains special characters."""
    if re.search(r"[^a-zA-Z0-9_]", value):
        return f"'{value}'"
    return value


def extract_vars(text: str, glossary_keys: List[str]) -> List[str]:
    """Extract all {variable} placeholders from a string, excluding glossary variables."""
    vars = re.findall(r'\{(.*?)\}', text)
    return [var for var in vars if var not in glossary_keys]


def vars_to_record_ts(variables: List[str]) -> List[List[str]]:
    """Convert variable names to [name, type] pairs."""
    arr = []
    for var in variables:
        var_type = 'number' if var in ('count', 'found_count') else 'string'
        to_append = [var, var_type]
        if to_append not in arr:
            arr.append(to_append)
    return arr


def format_tokens_with_named_args(token_args_dict: Dict[str, List[List[str]]]) -> str:
    """Format token->args mapping as TypeScript type."""
    if not token_args_dict:
        return "{}"

    result = []
    for token, args in token_args_dict.items():
        extras = []
        with_types = []

        for arg_name, arg_type in args:
            key = (arg_name, arg_type)
            if key in WITH_MAP:
                with_types.append(WITH_MAP[key])
            else:
                extras.append(f"{arg_name}: {arg_type}")

        joined = " & ".join(with_types)
        if extras:
            extras_str = "{ " + ", ".join(extras) + " }"
            joined = f"{joined} & {extras_str}" if joined else extras_str

        result.append(f"   {token}: {joined}")

    return "{\n" + ",\n".join(result) + "\n}"


def generate_with_types() -> str:
    """Generate the With* type definitions."""
    lines = []
    for (arg_name, arg_type), type_name in WITH_MAP.items():
        lines.append(f"type {type_name} = {{{arg_name}: {arg_type}}};")
    return "\n".join(lines)


def replace_glossary_variables(text: str, glossary_dict: Dict[str, str]) -> str:
    """Replace glossary variables like {app_name} with their actual values."""
    for glossary_key, glossary_value in glossary_dict.items():
        text = text.replace("{" + glossary_key + "}", glossary_value)
    return text


def snake_to_camel(snake_str: str) -> str:
    parts = snake_str.split('_')
    return parts[0].lower() + ''.join(word.capitalize() for word in parts[1:])


def convert_parsed_to_flat_locales(parsed_data: Dict[str, Any], is_qa_build: bool = False) -> Dict[str, Dict[str, str]]:
    """
    Convert parsed translation data to the flat locale format.
    Returns: { "en": {"key1": "value1", ...}, "de": {...}, ... }
    """
    source_language = parsed_data['source_language']
    target_languages = parsed_data['target_languages']
    locales_data = parsed_data['locales']
    glossary_dict = parsed_data.get('glossary', {})

    languages_to_process = [source_language] + \
        (['en'] if is_qa_build else target_languages)

    result = {}

    for lang in languages_to_process:
        orig_locale = lang['locale']
        locale_key = get_locale_key(orig_locale, lang['twoLettersCode'])

        locale_data = locales_data.get(orig_locale, {})
        translations = locale_data.get('translations', {})

        flat_translations = {}

        for key, trans_data in translations.items():
            if trans_data['type'] == 'plural':
                forms = trans_data['forms']
                parts = []
                for form, value in forms.items():
                    if form in ['zero', 'one', 'two', 'few', 'many', 'other']:
                        parts.append(f"{form} [{value}]")
                flat_translations[key] = "{count, plural, " + \
                    " ".join(parts) + "}"
            else:
                flat_translations[key] = trans_data['value']

        # Add glossary items to English locale (converted to camelCase)
        if locale_key == 'en':
            for glossary_key, glossary_value in glossary_dict.items():
                camel_key = snake_to_camel(glossary_key)
                flat_translations[camel_key] = glossary_value

        result[locale_key] = flat_translations

    return result


def categorize_strings(
    en_locale: Dict[str, str],
    glossary_dict: Dict[str, str]
) -> Tuple[List[str], Dict[str, List[List[str]]], Dict[str, List[List[str]]]]:
    """
    Categorize English strings into:
    - tokens_no_args: strings without dynamic variables
    - tokens_simple_with_args: simple strings with variables
    - tokens_plural_with_args: plural strings with variables

    Returns:
        (tokens_no_args, tokens_simple_with_args, tokens_plural_with_args)
    """
    glossary_keys = list(glossary_dict.keys())
    plural_pattern = r"(zero|one|two|few|many|other)\s*\[([^\]]+)\]"

    tokens_no_args = []
    tokens_simple_with_args = {}
    tokens_plural_with_args = {}

    for key, value_en in sorted(en_locale.items()):
        if value_en.startswith("{count, plural, "):
            # Plural string
            en_plurals_with_token = re.findall(plural_pattern, value_en)
            if en_plurals_with_token:
                extracted_vars = extract_vars(
                    en_plurals_with_token[0][1], glossary_keys)
                if 'count' not in extracted_vars:
                    extracted_vars.append('count')
                tokens_plural_with_args[key] = vars_to_record_ts(
                    extracted_vars)
        else:
            # Simple string
            replaced_value_en = replace_glossary_variables(
                value_en, glossary_dict)
            extracted_vars = extract_vars(replaced_value_en, glossary_keys)

            if extracted_vars:
                tokens_simple_with_args[key] = vars_to_record_ts(
                    extracted_vars)
            else:
                tokens_no_args.append(key)

    return tokens_no_args, tokens_simple_with_args, tokens_plural_with_args


def generate_english_dictionary(
    en_locale: Dict[str, str],
    glossary_dict: Dict[str, str],
    keys: List[str]
) -> str:
    """Generate a TypeScript dictionary for English strings."""
    lines = []
    for key in sorted(keys):
        if key not in en_locale:
            continue
        value = en_locale[key]
        # Replace glossary variables
        value = replace_glossary_variables(value, glossary_dict)
        escaped_value = escape_str(value)
        lines.append(f"  {wrap_value(key)}: \'{escaped_value}\'")

    return "{\n" + ",\n".join(lines) + ",\n}"


def generate_english_plural_dictionary(
    en_locale: Dict[str, str],
    glossary_dict: Dict[str, str],
    keys: List[str]
) -> str:
    plural_pattern = r"(zero|one|two|few|many|other)\s*\[([^\]]+)\]"
    entries = []

    for key in sorted(keys):
        if key not in en_locale:
            continue
        value = en_locale[key]
        plurals_with_token = re.findall(plural_pattern, value)

        form_lines = []
        for token, localized_string in plurals_with_token:
            replaced_string = replace_glossary_variables(
                localized_string, glossary_dict)
            form_lines.append(f"    {token}: \'{escape_str(replaced_string)}\'")

        entries.append(f"  {wrap_value(key)}: {{\n" + ",\n".join(form_lines) + ",\n  }")

    return "{\n" + ",\n".join(entries) + ",\n}"


def generate_sparse_translations(
    locales: Dict[str, Dict[str, str]],
    en_locale: Dict[str, str],
    glossary_dict: Dict[str, str],
    tokens_no_args: List[str],
    tokens_simple_with_args: Dict[str, Any],
    tokens_plural_with_args: Dict[str, Any]
) -> Tuple[str, str, str]:
    """
    Generate sparse translation dictionaries for non-English locales.
    Only includes strings that differ from English (actual translations).

    Returns:
        (simple_no_args_dict, simple_with_args_dict, plurals_dict)
    """
    plural_pattern = r"(zero|one|two|few|many|other)\s*\[([^\]]+)\]"

    # Get non-English locales
    other_locales = {k: v for k, v in locales.items() if k != 'en'}

    # Build sparse dictionaries
    sparse_no_args = {locale: {} for locale in other_locales}
    sparse_with_args = {locale: {} for locale in other_locales}
    sparse_plurals = {locale: {} for locale in other_locales}

    for locale, translations in other_locales.items():
        for key in tokens_no_args:
            en_value = replace_glossary_variables(
                en_locale.get(key, ""), glossary_dict)
            locale_value = replace_glossary_variables(
                translations.get(key, ""), glossary_dict)

            # Only include if different from English and not empty
            if locale_value and locale_value != en_value:
                sparse_no_args[locale][key] = locale_value

        for key in tokens_simple_with_args:
            en_value = replace_glossary_variables(
                en_locale.get(key, ""), glossary_dict)
            locale_value = replace_glossary_variables(
                translations.get(key, ""), glossary_dict)

            if locale_value and locale_value != en_value:
                sparse_with_args[locale][key] = locale_value

        for key in tokens_plural_with_args:
            en_value = en_locale.get(key, "")
            locale_value = translations.get(key, "")

            # For plurals, compare the full ICU string
            if locale_value and locale_value != en_value:
                # Parse and store plural forms
                plurals_with_token = re.findall(plural_pattern, locale_value)
                if plurals_with_token:
                    forms = {}
                    for token, localized_string in plurals_with_token:
                        replaced = replace_glossary_variables(
                            localized_string, glossary_dict)
                        forms[token] = replaced
                    sparse_plurals[locale][key] = forms

    # Generate TypeScript dictionaries
    def format_simple_sparse(sparse_dict: Dict[str, Dict[str, str]]) -> str:
        locale_entries = []
        for locale in sorted(sparse_dict.keys()):
            translations = sparse_dict[locale]
            if not translations:
                continue
            string_entries = []
            for key in sorted(translations.keys()):
                value = escape_str(translations[key])
                string_entries.append(f"    {wrap_value(key)}: \'{value}\'")
            locale_entries.append(f"  {wrap_value(locale)}: {{\n" + ",\n".join(string_entries) + ",\n  }")
        if not locale_entries:
            return "{}"
        return "{\n" + ",\n".join(locale_entries) + ",\n}"

    def format_plural_sparse(sparse_dict: Dict[str, Dict[str, Dict[str, str]]]) -> str:
        locale_entries = []
        for locale in sorted(sparse_dict.keys()):
            key_forms = sparse_dict[locale]
            if not key_forms:
                continue
            key_entries = []
            for key in sorted(key_forms.keys()):
                forms = key_forms[key]
                form_entries = []
                for form in ['zero', 'one', 'two', 'few', 'many', 'other']:
                    if form in forms:
                        form_entries.append(f"      {form}: \'{escape_str(forms[form])}\'")
                key_entries.append(f"    {wrap_value(key)}: {{\n" + ",\n".join(form_entries) + ",\n    }")
            locale_entries.append(f"  {wrap_value(locale)}: {{\n" + ",\n".join(key_entries) + ",\n  }")
        if not locale_entries:
            return "{}"
        return "{\n" + ",\n".join(locale_entries) + ",\n}"

    return (
        format_simple_sparse(sparse_no_args),
        format_simple_sparse(sparse_with_args),
        format_plural_sparse(sparse_plurals)
    )


def generate_english_ts(
    en_locale: Dict[str, str],
    glossary_dict: Dict[str, str],
    tokens_no_args: List[str],
    tokens_simple_with_args: Dict[str, Any],
    tokens_plural_with_args: Dict[str, Any],
    output_path: str
):
    simple_no_args_dict = generate_english_dictionary(
        en_locale, glossary_dict, tokens_no_args
    )
    simple_with_args_dict = generate_english_dictionary(
        en_locale, glossary_dict, list(tokens_simple_with_args.keys())
    )
    plural_dict = generate_english_plural_dictionary(
        en_locale, glossary_dict, list(tokens_plural_with_args.keys())
    )

    content = f"""{DISCLAIMER_GENERATED}{DISCLAIMER_ENGLISH}import type {{ TokenSimpleNoArgs, TokenSimpleWithArgs, TokenPluralWithArgs, PluralForms }} from './locales';

/** English strings without dynamic arguments */
export const enSimpleNoArgs = {simple_no_args_dict} as const satisfies Record<TokenSimpleNoArgs, string>;

/** English strings with dynamic arguments */
export const enSimpleWithArgs = {simple_with_args_dict} as const satisfies Record<TokenSimpleWithArgs, string>;

/** English plural strings */
export const enPlurals = {plural_dict} as const satisfies Record<TokenPluralWithArgs, PluralForms>;
"""

    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)

    print_success(f"Generated {output_path}")


def generate_translations_ts(
    locales: Dict[str, Dict[str, str]],
    en_locale: Dict[str, str],
    glossary_dict: Dict[str, str],
    tokens_no_args: List[str],
    tokens_simple_with_args: Dict[str, Any],
    tokens_plural_with_args: Dict[str, Any],
    output_path: str
):
    sparse_no_args, sparse_with_args, sparse_plurals = generate_sparse_translations(
        locales, en_locale, glossary_dict,
        tokens_no_args, tokens_simple_with_args, tokens_plural_with_args
    )

    # Get list of non-English locales
    other_locales = sorted([k for k in locales.keys() if k != 'en'])
    other_locales_type = " | ".join(f"'{locale}'" for locale in other_locales)

    content = f"""{DISCLAIMER_GENERATED}import type {{ TokenSimpleNoArgs, TokenSimpleWithArgs, TokenPluralWithArgs, PluralForms }} from './locales';

/** Non-English locale codes */
export type TranslationLocale = {other_locales_type};

/** Sparse translations for simple strings without arguments (only actual translations, no English duplicates) */
export const translationsSimpleNoArgs: Partial<Record<TranslationLocale, Partial<Record<TokenSimpleNoArgs, string>>>> = {sparse_no_args} as const;

/** Sparse translations for simple strings with arguments */
export const translationsSimpleWithArgs: Partial<Record<TranslationLocale, Partial<Record<TokenSimpleWithArgs, string>>>> = {sparse_with_args} as const;

/** Sparse translations for plural strings */
export const translationsPlurals: Partial<Record<TranslationLocale, Partial<Record<TokenPluralWithArgs, PluralForms>>>> = {sparse_plurals} as const;
"""

    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)

    print_success(f"Generated {output_path}")


def generate_locales_ts(
    tokens_no_args: List[str],
    tokens_simple_with_args: Dict[str, Any],
    tokens_plural_with_args: Dict[str, Any],
    locales: Dict[str, Dict[str, str]],
    rtl_languages: List[Dict],
    glossary_dict: Dict[str, str],
    output_path: str
):
    """Generate locales.ts - types, and utility functions."""
    # Token type strings
    tokens_no_args_str = "\n  '" + \
        "' |\n  '".join(tokens_no_args) + "'" if tokens_no_args else "never"
    tokens_simple_with_args_str = "\n  '" + "' |\n  '".join(list(
        tokens_simple_with_args.keys())) + "'" if tokens_simple_with_args else "never"
    tokens_plural_with_args_str = "\n  '" + "' |\n  '".join(list(
        tokens_plural_with_args.keys())) + "'" if tokens_plural_with_args else "never"

    tokens_union_simple_args = format_tokens_with_named_args(
        tokens_simple_with_args)
    tokens_union_plural_args = format_tokens_with_named_args(
        tokens_plural_with_args)

    content = f"""{DISCLAIMER_GENERATED}// Re-export English strings and translations
export {{ enSimpleNoArgs, enSimpleWithArgs, enPlurals }} from './english';
export {{ translationsSimpleNoArgs, translationsSimpleWithArgs, translationsPlurals, type TranslationLocale }} from './translations';

// ============================================================================
// Type Definitions
// ============================================================================

{generate_with_types()}

/** Plural form keys */
export type PluralForm = 'zero' | 'one' | 'two' | 'few' | 'many' | 'other';

/** Plural forms object */
export type PluralForms = Partial<Record<PluralForm, string>>;

/** Token keys for simple strings without arguments */
export type TokenSimpleNoArgs = {tokens_no_args_str};

/** Token keys for simple strings with arguments */
export type TokenSimpleWithArgs = {tokens_simple_with_args_str};

/** Token keys for plural strings */
export type TokenPluralWithArgs = {tokens_plural_with_args_str};

/** Argument types for simple strings with arguments */
export type TokensSimpleAndArgs = {tokens_union_simple_args};

/** Argument types for plural strings */
export type TokensPluralAndArgs = {tokens_union_plural_args};
"""

    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)

    print_success(f"Generated {output_path}")


def generate_constants_ts(
    locales: Dict[str, Dict[str, str]],
    rtl_languages: List[Dict],
    output_path: str
):
    all_locales = sorted(locales.keys())
    rtl_locales = sorted([lang["twoLettersCode"] for lang in rtl_languages])

    crowdin_locales_str = ",".join(f"\n  '{locale}'" for locale in all_locales)
    rtl_locales_str = ", ".join(f"'{locale}'" for locale in rtl_locales)

    content = f"""{DISCLAIMER_GENERATED}
/** Right-to-left locale codes */
export const rtlLocales = [{rtl_locales_str}];

/** All supported Crowdin locale codes */
export const crowdinLocales = [{crowdin_locales_str},
] as const;

/** Crowdin locale type */
export type CrowdinLocale = (typeof crowdinLocales)[number];

/** Type guard for CrowdinLocale */
export function isCrowdinLocale(locale: string): locale is CrowdinLocale {{
  return crowdinLocales.indexOf(locale as CrowdinLocale) !== -1;
}}
"""

    os.makedirs(os.path.dirname(output_path) or '.', exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)

    print_success(f"Generated {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description='Generate Desktop localization files from parsed translations'
    )
    parser.add_argument(
        'parsed_translations_file',
        help='Path to the parsed translations JSON file'
    )
    parser.add_argument(
        'output_directory',
        help='Directory to write the output files (locales.ts, english.ts, translations.ts)'
    )
    parser.add_argument(
        '--qa-build',
        action='store_true',
        help='Generate only English translations (for QA builds)'
    )
    args = parser.parse_args()

    # Load parsed data
    print_progress("Loading parsed translations...")
    parsed_data = load_parsed_translations(args.parsed_translations_file)
    glossary_dict = parsed_data.get('glossary', {})
    rtl_languages = parsed_data.get('rtl_languages', [])

    # Convert to flat locale format
    print_progress("Converting parsed translations to locale format...")
    locales = convert_parsed_to_flat_locales(parsed_data, args.qa_build)
    en_locale = locales.get('en', {})

    # Categorize strings
    print_progress("Categorizing strings...")
    tokens_no_args, tokens_simple_with_args, tokens_plural_with_args = categorize_strings(
        en_locale, glossary_dict
    )

    # Calculate statistics
    total_tokens = len(tokens_no_args) + \
        len(tokens_simple_with_args) + len(tokens_plural_with_args)
    print_success(f"Found {total_tokens} total tokens:")
    print_success(f"  - {len(tokens_no_args)} simple without args")
    print_success(f"  - {len(tokens_simple_with_args)} simple with args")
    print_success(f"  - {len(tokens_plural_with_args)} plurals")

    # Generate output files
    output_dir = args.output_directory
    os.makedirs(output_dir, exist_ok=True)

    # Generate english.ts
    print_progress("Generating english.ts...")
    generate_english_ts(
        en_locale, glossary_dict,
        tokens_no_args, tokens_simple_with_args, tokens_plural_with_args,
        os.path.join(output_dir, 'english.ts')
    )

    # Generate translations.ts
    print_progress("Generating translations.ts...")
    generate_translations_ts(
        locales, en_locale, glossary_dict,
        tokens_no_args, tokens_simple_with_args, tokens_plural_with_args,
        os.path.join(output_dir, 'translations.ts')
    )

    # Generate locales.ts
    print_progress("Generating locales.ts...")
    generate_locales_ts(
        tokens_no_args, tokens_simple_with_args, tokens_plural_with_args,
        locales, rtl_languages, glossary_dict,
        os.path.join(output_dir, 'locales.ts')
    )

    # Generate constants.ts (for backwards compatibility)
    print_progress("Generating constants.ts...")
    generate_constants_ts(
        locales, rtl_languages,
        os.path.join(output_dir, 'constants.ts')
    )

    print_success("All files generated successfully!")


if __name__ == "__main__":
    run_main(main)
